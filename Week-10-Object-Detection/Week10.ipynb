{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "726d6a86-0599-45bd-8915-fe9a43ffed5b",
   "metadata": {},
   "source": [
    "# Week 10\n",
    "\n",
    "This week and next week, we will be moving beyond image classification and focus on a new task: object detection. This requires us to localize and classify objects from multiple classes in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286b0916-2289-4d09-8c9b-2fb76769f2fe",
   "metadata": {},
   "source": [
    "# Lecture 18 - Classical Object Detection\n",
    "\n",
    "Below we import some libraries and write some utility functions.\n",
    "\n",
    "**Note**: Some code here is adapted from https://www.pyimagesearch.com/2020/06/22/turning-any-cnn-image-classifier-into-an-object-detector-with-keras-tensorflow-and-opencv/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cf6b68-0038-487f-9f0c-592a665c2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "def sliding_window(image, stride, wh):\n",
    "    # slide window vertically\n",
    "    for y in range(0, image.shape[0] - wh[1], stride):\n",
    "        \n",
    "        # slide window horizontally\n",
    "        for x in range(0, image.shape[1] - wh[0], stride):\n",
    "            \n",
    "            # yield the lower left corner of the window and the window\n",
    "            yield (x, y, image[y:y + wh[1], x:x + wh[0]])\n",
    "            \n",
    "def image_pyramid(image, scale = 2, minSize = (224, 224)):\n",
    "    # yield the original window\n",
    "    yield image\n",
    "    \n",
    "    while True:\n",
    "        # find the dimensions of the next image in the pydamid\n",
    "        w = int(image.shape[1] / scale)\n",
    "        \n",
    "        # resize the image while maintaining aspect ratio\n",
    "        image = imutils.resize(image, width = int(image.shape[1] / scale))\n",
    "        \n",
    "        # if the image is below the min size, stop\n",
    "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "            break\n",
    "            \n",
    "        # yield the next image in the pyramid\n",
    "        yield image\n",
    "        \n",
    "#  Felzenszwalb et al.\n",
    "def non_max_suppression_slow(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "    \n",
    "    # get coordinates of the bounding boxes\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    \n",
    "    # compute the area of the bounding boxes and sort by the bottom-right y-coordinate\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    \n",
    "    # loop over the indexes\n",
    "    while len(idxs) > 0:\n",
    "        # get last index in the indexes list\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        \n",
    "        # add the index value to the list of picked indexes\n",
    "        pick.append(i)\n",
    "        \n",
    "        # initialize the suppression list using the last index\n",
    "        suppress = [last]\n",
    "        \n",
    "        # loop over all indexes in list\n",
    "        for pos in range(last):\n",
    "            # get the current index\n",
    "            j = idxs[pos]\n",
    "            \n",
    "            # find min and max (x, y) coordinates for the bounding box\n",
    "            xx1 = max(x1[i], x1[j])\n",
    "            yy1 = max(y1[i], y1[j])\n",
    "            xx2 = min(x2[i], x2[j])\n",
    "            yy2 = min(y2[i], y2[j])\n",
    "            \n",
    "            # compute the width and height of the bounding box\n",
    "            w = max(0, xx2 - xx1 + 1)\n",
    "            h = max(0, yy2 - yy1 + 1)\n",
    "            \n",
    "            # compute the ratio of overlap between the computed bounding box and the bounding box in the area list\n",
    "            overlap = float(w * h) / area[j]\n",
    "            \n",
    "            # if there is sufficient overlap, suppress the current bounding box\n",
    "            if overlap > overlapThresh:\n",
    "                suppress.append(pos)\n",
    "        \n",
    "        # delete all indexes in the suppression list\n",
    "        idxs = np.delete(idxs, suppress)\n",
    "        \n",
    "    # return the bounding boxes that were picked\n",
    "    return boxes[pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40ce8792-c7fc-4272-b26d-f51e7d554503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac2e45-f7c5-4e1a-93e9-63774cda79cf",
   "metadata": {},
   "source": [
    "## Transfer Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0871cbe7-85dd-42be-9281-62f4b5886991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables used for the object detection procedure\n",
    "WIDTH = 800\n",
    "P_SCALE = 1.5\n",
    "WIN_STRIDE = 4\n",
    "#ROI_SIZE = (550, 350)\n",
    "ROI_SIZE = (250, 300)\n",
    "INPUT_SIZE = (224, 224)\n",
    "IMAGE = 'cat_dog.jpg'\n",
    "VIZ = False\n",
    "MINCONF = 0.8\n",
    "OVERLAP_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeff1f5e-6c19-4b94-bdaa-cf74d8610a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading network...\n",
      "new pyramid image\n",
      "looping over pyramid/windows took 1.654421091079712 s\n",
      "classifying ROIs...\n",
      "classifying ROIs took 7.001559734344482 s\n",
      "showing results for Brabancon_griffon\n",
      "applying NMS...\n",
      "showing results for Bouvier_des_Flandres\n",
      "applying NMS...\n",
      "showing results for Labrador_retriever\n",
      "applying NMS...\n",
      "showing results for Egyptian_cat\n",
      "applying NMS...\n"
     ]
    }
   ],
   "source": [
    "# load ResNet pretrained on ImageNet\n",
    "print(\"loading network...\")\n",
    "model = ResNet50(weights = 'imagenet', include_top=True)\n",
    "\n",
    "# load the input image, resize to specified width, and find the new dimensions\n",
    "original = cv2.imread(IMAGE)\n",
    "original = imutils.resize(original, width = WIDTH)\n",
    "H, W = original.shape[:2]\n",
    "\n",
    "# initialize image pyramid\n",
    "pyramid = image_pyramid(original, scale = P_SCALE, minSize = ROI_SIZE)\n",
    "\n",
    "# initialize a list for ROIs from the pyramid and sliding windows\n",
    "rois = []\n",
    "\n",
    "# initialize a list for coordinates in the original image for the ROIs\n",
    "locs = []\n",
    "\n",
    "# start a timer\n",
    "start = time.time()\n",
    "\n",
    "# preprocess images from pyramid\n",
    "for image in pyramid:\n",
    "    print('new pyramid image')\n",
    "    # find the scale between the original image and current layer of pyramid\n",
    "    scale = W / float(image.shape[1])\n",
    "\n",
    "    # loop over sliding window locations\n",
    "    for x, y, roiOriginal in sliding_window(image, WIN_STRIDE, ROI_SIZE):\n",
    "        # scale coordinates of ROI\n",
    "        x = int(x * scale)\n",
    "        y = int(y * scale)\n",
    "        w = int(ROI_SIZE[0] * scale)\n",
    "        h = int(ROI_SIZE[1] * scale)\n",
    "        \n",
    "        # preprocess ROI\n",
    "        roi = cv2.resize(roiOriginal, INPUT_SIZE)\n",
    "        roi = img_to_array(roi)\n",
    "        roi = preprocess_input(roi)\n",
    "        \n",
    "        # update list of ROIs and coordinates\n",
    "        rois.append(roi)\n",
    "        locs.append((x, y, x + w, y + h))\n",
    "        \n",
    "        if VIZ:\n",
    "            # clone image and draw a bounding box\n",
    "            clone = original.copy()\n",
    "            cv2.rectangle(clone, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # show visualization of current ROI\n",
    "            cv2.imshow('Visualization', clone)\n",
    "            cv2.imshow('ROI', roiOriginal)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "end = time.time()\n",
    "\n",
    "print('looping over pyramid/windows took', end - start, 's')\n",
    "\n",
    "# convert ROIs to numpy array\n",
    "rois = np.array(rois, dtype = 'float32')\n",
    "\n",
    "# classify each proposal with ResNet\n",
    "print('classifying ROIs...')\n",
    "start = time.time()\n",
    "preds = model.predict(rois)\n",
    "end = time.time()\n",
    "\n",
    "print('classifying ROIs took', end - start, 's')\n",
    "\n",
    "predictions = imagenet_utils.decode_predictions(preds, top = 1)\n",
    "labels = {}\n",
    "\n",
    "# loop over the predictions\n",
    "for (i, p) in enumerate(predictions):\n",
    "    # get the prediction information for the current ROI\n",
    "    imagenetID, label, prob = p[0]\n",
    "\n",
    "    # filter out weak detections\n",
    "    if prob >= MINCONF:\n",
    "        # get bounding box associated with the prediction and\n",
    "        # convert the coordinates\n",
    "        box = locs[i]\n",
    "        \n",
    "        # get predictions for the label and add the bounding box and probability to the list\n",
    "        L = labels.get(label, [])\n",
    "        L.append((box, prob))\n",
    "        labels[label] = L\n",
    "        \n",
    "# loop over the labels for each of detected objects in the image\n",
    "for label in labels.keys():\n",
    "    # clone the original image\n",
    "    print('showing results for', label)\n",
    "    clone = original.copy()\n",
    "    \n",
    "    # loop over all bounding boxes for the current label\n",
    "    for box, prob in labels[label]:\n",
    "        # draw the bounding box on the image\n",
    "        startX, startY, endX, endY = box\n",
    "        cv2.rectangle(clone, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "    \n",
    "    # show the results before NMS\n",
    "    cv2.imshow('Before NMS', clone)\n",
    "    clone = original.copy()\n",
    "    \n",
    "    # extract the bounding boxes and prediction probabilities\n",
    "    boxes = np.array([p[0] for p in labels[label]])\n",
    "    proba = np.array([p[1] for p in labels[label]])\n",
    "    \n",
    "    # apply NMS\n",
    "    print('applying NMS...')\n",
    "    boxes = non_max_suppression_slow(boxes, OVERLAP_THRESHOLD)\n",
    "    \n",
    "    # loop over all bounding boxes that were kept after applying NMS\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "        \n",
    "        # draw the bounding box and label on the image\n",
    "        cv2.rectangle(clone, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        \n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "        \n",
    "        cv2.putText(clone, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "        \n",
    "    # show the output after apply non-maxima suppression\n",
    "    cv2.imshow('After NMS', clone)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6f3323-9a13-4f09-9fd0-7509da762e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
